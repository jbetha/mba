{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPH4q6f26xuODx8LLKe7aDl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Analise de sentimentos de assédio moral"],"metadata":{"id":"sUiXejkkl3SH"}},{"cell_type":"code","source":["# Instalar bibliotecas necessárias\n","!pip install nltk textblob matplotlib pandas scikit-learn requests\n","\n","# Importar bibliotecas\n","import nltk\n","from textblob import TextBlob\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from collections import Counter\n","import requests\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import make_pipeline\n","from sklearn import metrics\n","\n","# Baixar dados de análise de sentimentos do nltk\n","nltk.download('punkt')\n","\n","# Função para ler o arquivo CSV de treinamento a partir de uma URL\n","def ler_csv_url(url):\n","    df = pd.read_csv(url)\n","    return df\n","\n","# Função para preparar os dados a partir de um dataframe CSV\n","def preparar_dados_csv(df):\n","    # Verifica se o arquivo tem as colunas necessárias\n","    if 'fala' not in df.columns or 'comportamento' not in df.columns:\n","        raise ValueError(\"O arquivo CSV não contém as colunas 'fala' e 'comportamento'.\")\n","\n","    textos = df['fala'].tolist()\n","    etiquetas = df['comportamento'].tolist()\n","\n","    print(f\"Número de amostras para treinamento: {len(textos)}\")\n","\n","    if not textos:\n","        print(\"Aviso: Nenhuma amostra de treinamento foi preparada.\")\n","\n","    return textos, etiquetas\n","\n","# Função para treinar o modelo de classificação para detectar padrões abusivos\n","def treinar_modelo(textos_treinamento, etiquetas_treinamento):\n","    if len(textos_treinamento) == 0:\n","        raise ValueError(\"Nenhuma amostra de treinamento foi fornecida.\")\n","\n","    # Dividir dados em treinamento e teste\n","    X_train, X_test, y_train, y_test = train_test_split(textos_treinamento, etiquetas_treinamento, test_size=0.2, random_state=42)\n","\n","    # Criar e treinar o modelo de NLP\n","    model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n","    model.fit(X_train, y_train)\n","\n","    # Avaliação do Modelo\n","    y_pred = model.predict(X_test)\n","    print(\"Acurácia:\", metrics.accuracy_score(y_test, y_pred))\n","    print(\"Precisão:\", metrics.precision_score(y_test, y_pred, average='weighted'))\n","    print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='weighted'))\n","    print(\"F1-score:\", metrics.f1_score(y_test, y_pred, average='weighted'))\n","\n","    return model\n","\n","# Função para ler o texto a partir de uma URL\n","def ler_texto_url(url):\n","    response = requests.get(url)\n","    return response.text\n","\n","# Função para avaliar o modelo em novos dados\n","def avaliar_modelo(modelo, url_teste):\n","    texto_teste = ler_texto_url(url_teste)\n","    if texto_teste:\n","        # Preparar dados para o conjunto de teste\n","        textos, _ = preparar_dados_csv(pd.DataFrame({'fala': [texto_teste], 'comportamento': [None]}))\n","        if len(textos) > 0:\n","            predicoes = modelo.predict(textos)\n","            print(\"Classificações:\", predicoes)\n","        else:\n","            print(\"Nenhuma amostra disponível para avaliação.\")\n","    else:\n","        print(\"Nenhum texto disponível para avaliação.\")\n","\n","# URLs dos arquivos de treinamento, teste e validação\n","url_treinamento = 'https://raw.githubusercontent.com/jbetha/mba/main/Analise_Sentimento_Assedio_dados_treinamento.csv'\n","url_teste = 'https://raw.githubusercontent.com/jbetha/mba/main/Alinhamento%20-%20Solu%C3%A7%C3%B5es%20T%C3%A9cnicas%20Transcript-1_23082024.txt'\n","url_validacao = 'https://raw.githubusercontent.com/jbetha/mba/main/Alinhamento%20de%20atividades%20Transcript_16082024.txt'\n","\n","# Ler o arquivo CSV de treinamento\n","df_treinamento = ler_csv_url(url_treinamento)\n","\n","# Preparar dados para treinamento a partir do CSV\n","textos_treinamento, etiquetas_treinamento = preparar_dados_csv(df_treinamento)\n","\n","# Verificar se há dados suficientes para treinamento\n","if len(textos_treinamento) > 0:\n","    # Treinar o modelo de classificação\n","    modelo_comportamentos = treinar_modelo(textos_treinamento, etiquetas_treinamento)\n","\n","    # Avaliar o modelo com o conjunto de teste\n","    print(\"Avaliação do Modelo com o Conjunto de Teste:\")\n","    avaliar_modelo(modelo_comportamentos, url_teste)\n","\n","    # Avaliar o modelo com o conjunto de validação\n","    print(\"Avaliação do Modelo com o Conjunto de Validação:\")\n","    avaliar_modelo(modelo_comportamentos, url_validacao)\n","else:\n","    print(\"Não há dados suficientes para treinamento do modelo.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOsu909jslmE","executionInfo":{"status":"ok","timestamp":1726081092355,"user_tz":180,"elapsed":8614,"user":{"displayName":"Jaguaraci Silva","userId":"14528760357252352543"}},"outputId":"3e7a9f92-f1d8-4ae4-c2f6-6713cc05a404"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Número de amostras para treinamento: 22\n","Acurácia: 0.4\n","Precisão: 0.16\n","Recall: 0.4\n","F1-score: 0.2285714285714286\n","Avaliação do Modelo com o Conjunto de Teste:\n","Número de amostras para treinamento: 1\n","Classificações: ['desvalorização']\n","Avaliação do Modelo com o Conjunto de Validação:\n","Número de amostras para treinamento: 1\n","Classificações: ['desvalorização']\n"]}]},{"cell_type":"markdown","source":["Para melhorar o modelo com base nos seus objetivos, aqui está um plano de ação:\n","\n","# 1. Pré-processamento e Limpeza de Texto:\n","\n","*   Limpeza: Remover stopwords, pontuação, números e converter texto para minúsculas.\n","*   Normalização: Remover acentuação e realizar stemming/lemmatização.\n","*   Balanceamento: Uso de técnicas de balanceamento para lidar com classes desbalanceadas, como Random Oversampling ou SMOTE (Synthetic Minority Over-sampling Technique).\n","\n","# 2. Ajustes de Hiperparâmetros:\n","\n","*   TfidfVectorizer: ngram_range: Ajustar para considerar combinações de palavras (bi-gramas ou tri-gramas).\n","*   max_df e min_df: Remover termos muito frequentes ou muito raros.\n","*   max_features: Limitar o número de termos para evitar sobreajuste.\n","*   MultinomialNB: Ajuste da suavização Laplace (alpha).\n","\n","# 3. Validação Cruzada e Análise de Erros:\n","*   Implementar validação cruzada com K-fold para avaliar o desempenho do modelo.\n","*   Detalhar erros de classificação para entender onde o modelo falha."],"metadata":{"id":"m_3wX-ay_Os9"}},{"cell_type":"code","source":["# Instalar bibliotecas necessárias\n","!pip install nltk textblob scikit-learn pandas imbalanced-learn unidecode\n","\n","# Importar bibliotecas\n","import nltk\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split, cross_val_predict\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.pipeline import make_pipeline\n","from sklearn.utils import resample\n","from imblearn.over_sampling import RandomOverSampler\n","from collections import Counter\n","import pandas as pd\n","import re\n","import unidecode\n","\n","# Baixar stopwords do nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","# Função de pré-processamento de texto\n","def preprocess_text(text):\n","    text = text.lower()  # Converte para minúsculas\n","    text = unidecode.unidecode(text)  # Remove acentuação\n","    text = re.sub(r'\\d+', '', text)  # Remove números\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove pontuação\n","    stop_words = set(stopwords.words('portuguese'))  # Carrega stopwords em português\n","    tokens = [word for word in text.split() if word not in stop_words]  # Remove stopwords\n","    return \" \".join(tokens)\n","\n","# Função para balancear as classes\n","def balancear_dados(X, y):\n","    X = X.values.reshape(-1, 1)  # Transformar X em um array 2D\n","    ros = RandomOverSampler(random_state=42)\n","    X_resampled, y_resampled = ros.fit_resample(X, y)\n","\n","    # Convertendo de volta para uma lista 1D\n","    X_resampled = [x[0] for x in X_resampled]\n","\n","    print(f\"Classes balanceadas: {Counter(y_resampled)}\")\n","    return X_resampled, y_resampled\n","\n","# Função para treinar o modelo de classificação com validação cruzada\n","def treinar_modelo_cv(textos, etiquetas):\n","    # Ajuste do TfidfVectorizer e MultinomialNB\n","    vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.9, min_df=5, max_features=5000)\n","    model = make_pipeline(vectorizer, MultinomialNB(alpha=0.1))\n","\n","    # Validação cruzada\n","    y_pred = cross_val_predict(model, textos, etiquetas, cv=5)\n","\n","    # Análise de desempenho\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(etiquetas, y_pred))\n","    print(\"Matriz de Confusão:\")\n","    print(confusion_matrix(etiquetas, y_pred))\n","\n","    return model\n","\n","# URL dos dados de treinamento\n","url_treinamento = 'https://raw.githubusercontent.com/jbetha/mba/refs/heads/main/Analise_Sentimento_Assedio_dados_treinamento.csv'\n","\n","# Ler o arquivo CSV\n","df_treinamento = pd.read_csv(url_treinamento)\n","\n","# Verificar colunas necessárias e pré-processar os textos\n","if 'fala' not in df_treinamento.columns or 'comportamento' not in df_treinamento.columns:\n","    raise ValueError(\"O arquivo CSV não contém as colunas 'fala' e 'comportamento'.\")\n","df_treinamento['fala_limpa'] = df_treinamento['fala'].apply(preprocess_text)\n","\n","# Balancear os dados\n","textos, etiquetas = balancear_dados(df_treinamento['fala_limpa'], df_treinamento['comportamento'])\n","\n","# Treinar o modelo com validação cruzada\n","modelo = treinar_modelo_cv(textos, etiquetas)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHGc-VUK_hcH","executionInfo":{"status":"ok","timestamp":1726929313742,"user_tz":180,"elapsed":3101,"user":{"displayName":"Jaguaraci Silva","userId":"14528760357252352543"}},"outputId":"90c92e2f-1eca-41db-e3fd-4775a846ce66"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Classes balanceadas: Counter({'desvalorização': 11, 'vida_privada': 11, 'delegação_inadequada': 11})\n","Relatório de Classificação:\n","                      precision    recall  f1-score   support\n","\n","delegação_inadequada       0.57      0.36      0.44        11\n","      desvalorização       0.56      0.82      0.67        11\n","        vida_privada       0.90      0.82      0.86        11\n","\n","            accuracy                           0.67        33\n","           macro avg       0.68      0.67      0.66        33\n","        weighted avg       0.68      0.67      0.66        33\n","\n","Matriz de Confusão:\n","[[4 6 1]\n"," [2 9 0]\n"," [1 1 9]]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["# 1. Acurácia Geral\n","A acurácia geral do modelo é 67%, o que significa que o modelo está classificando corretamente 67% das amostras. Isso indica uma melhora em relação aos resultados anteriores, porém ainda pode haver espaço para aprimoramentos, especialmente no balanceamento das classes e na melhoria da generalização do modelo.\n","\n","# 2. Análise por Classe:\n","**delegação inadequada:**\n","\n","*  Precisão: 0.57 (57%) Dos exemplos classificados como \"delegação inadequada\", apenas 57% estavam corretos. Isso indica que o modelo está fazendo uma quantidade razoável de classificações erradas para esta classe.\n","*  Recall: 0.36 (36%) Apenas 36% dos exemplos reais de \"delegação inadequada\" foram identificados corretamente pelo modelo. Isso é um sinal de que o modelo está tendo dificuldades em identificar essa classe de forma consistente.\n","*  F1-score: 0.44 O F1-score médio (harmonização entre precisão e recall) é 44%, o que mostra que essa classe ainda é a mais desafiadora para o modelo.\n","\n","**desvalorização:**\n","\n","*  Precisão: 0.56 (56%) 56% dos exemplos classificados como \"desvalorização\" estavam corretos. Este valor é moderado.\n","*  Recall: 0.82 (82%) O modelo é muito bom em identificar a classe \"desvalorização\", com 82% dos exemplos reais sendo corretamente classificados.\n","*  F1-score: 0.67 A classe \"desvalorização\" apresenta um equilíbrio melhor, com um F1-score de 67%, indicando que o modelo lida razoavelmente bem com essa classe.\n","\n","**vida privada:**\n","\n","*  Precisão: 0.90 (90%) O modelo tem uma precisão alta ao classificar a classe \"vida privada\", com 90% das classificações para essa classe sendo corretas.\n","*  Recall: 0.82 (82%) O recall é também alto, indicando que a maioria dos exemplos reais de \"vida privada\" são corretamente identificados.\n","*  F1-score: 0.86 O F1-score de 86% mostra que o modelo se sai muito bem com essa classe, tanto em termos de precisão quanto de recall.\n","\n","# 3. Matriz de Confusão:\n","A matriz de confusão apresenta a distribuição dos erros e acertos do modelo para cada classe:\n","\n","[[4 6 1]  -> delegação inadequada\n"," [2 9 0]  -> desvalorização\n"," [1 1 9]] -> vida privada\n","\n","**delegação inadequada:**\n","*  4 exemplos foram classificados corretamente.\n","*  6 exemplos de \"delegação inadequada\" foram erroneamente classificados como \"desvalorização\".\n","*  1 exemplo foi classificado incorretamente como \"vida privada\".\n","\n","**desvalorização:**\n","*  9 exemplos foram classificados corretamente.\n","*  2 exemplos de \"desvalorização\" foram erroneamente classificados como \"delegação inadequada\".\n","\n","**vida privada:**\n","*  9 exemplos foram classificados corretamente.\n","*  1 exemplo de \"vida privada\" foi classificado como \"delegação inadequada\".\n","*  1 exemplo foi erroneamente classificado como \"desvalorização\".\n","\n","# 4. Sugestões para Melhorias:\n","* Classe \"delegação inadequada\": O modelo tem maior dificuldade com essa classe, com baixo recall (36%) e muitos exemplos erroneamente classificados como \"desvalorização\". **Uma possível melhoria seria aumentar o número de amostras para essa classe ou aplicar técnicas de aumento de dados.**\n","\n","* Classe \"desvalorização\": Embora o recall seja alto, a precisão pode ser melhorada. O modelo pode estar classificando exemplos incorretamente como \"desvalorização\", sugerindo um possível desequilíbrio ou confusão entre classes.\n","\n","* Classe \"vida privada\": Esta é a classe mais fácil para o modelo, com alto F1-score e poucos erros. O modelo lida bem com essa categoria."],"metadata":{"id":"hONoJyreCaR0"}},{"cell_type":"code","source":["# Importar bibliotecas\n","import nltk\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from sklearn import metrics\n","from imblearn.over_sampling import RandomOverSampler\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","# Baixar dados de análise de sentimentos do nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Função para ler o arquivo CSV de treinamento a partir de uma URL\n","def ler_csv_url(url):\n","    df = pd.read_csv(url)\n","    return df\n","\n","# Função para pré-processamento do texto: limpeza, remoção de stopwords e lematização\n","def preprocessamento_texto(textos):\n","    stop_words = set(stopwords.words('portuguese'))\n","    lemmatizer = WordNetLemmatizer()\n","\n","    textos_limpos = []\n","    for texto in textos:\n","        # Tokenizar e remover pontuação\n","        palavras = nltk.word_tokenize(texto.lower())\n","        palavras = [palavra for palavra in palavras if palavra.isalpha()]  # Mantém apenas palavras\n","\n","        # Remover stopwords e aplicar lematização\n","        palavras = [lemmatizer.lemmatize(palavra) for palavra in palavras if palavra not in stop_words]\n","        textos_limpos.append(\" \".join(palavras))\n","\n","    return textos_limpos\n","\n","# Função para balancear os dados com RandomOverSampler\n","def balancear_dados(X_train, y_train):\n","    ros = RandomOverSampler(random_state=42)\n","    X_res, y_res = ros.fit_resample(X_train, y_train)\n","    return X_res, y_res\n","\n","# Função para treinar o modelo com validação cruzada e ajuste de hiperparâmetros\n","def treinar_modelo(textos_treinamento, etiquetas_treinamento):\n","    # Dividir dados em treinamento e teste\n","    X_train, X_test, y_train, y_test = train_test_split(textos_treinamento, etiquetas_treinamento, test_size=0.2, random_state=42)\n","\n","    # Vetorizar o texto\n","    vectorizer = TfidfVectorizer(max_df=0.8, ngram_range=(1, 2))\n","    X_train_vect = vectorizer.fit_transform(X_train)\n","    X_test_vect = vectorizer.transform(X_test)\n","\n","    # Balancear os dados usando RandomOverSampler\n","    X_train_bal, y_train_bal = balancear_dados(X_train_vect, y_train)\n","\n","    # Treinar o modelo MultinomialNB\n","    modelo = MultinomialNB(alpha=0.1)\n","    modelo.fit(X_train_bal, y_train_bal)\n","\n","    # Avaliar o modelo\n","    y_pred = modelo.predict(X_test_vect)\n","    print(\"Acurácia:\", metrics.accuracy_score(y_test, y_pred))\n","    print(\"Precisão:\", metrics.precision_score(y_test, y_pred, average='weighted'))\n","    print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='weighted'))\n","    print(\"F1-score:\", metrics.f1_score(y_test, y_pred, average='weighted'))\n","\n","    # Matriz de confusão\n","    print(\"Matriz de Confusão:\")\n","    print(metrics.confusion_matrix(y_test, y_pred))\n","\n","    return modelo\n","\n","# URLs dos arquivos de treinamento\n","url_treinamento = 'https://raw.githubusercontent.com/jbetha/mba/refs/heads/main/Analise_Sentimento_Assedio_dados_treinamento.csv'\n","\n","# Ler o arquivo CSV de treinamento\n","df_treinamento = ler_csv_url(url_treinamento)\n","\n","# Pré-processar os textos de treinamento\n","df_treinamento['fala_limpa'] = preprocessamento_texto(df_treinamento['fala'])\n","\n","# Treinar o modelo com validação cruzada e ajuste de hiperparâmetros\n","modelo_comportamentos = treinar_modelo(df_treinamento['fala_limpa'], df_treinamento['comportamento'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7_MABCcF06v","executionInfo":{"status":"ok","timestamp":1726931007239,"user_tz":180,"elapsed":584,"user":{"displayName":"Jaguaraci Silva","userId":"14528760357252352543"}},"outputId":"e96af97c-a9cd-4941-f381-2fe9f37090c8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Acurácia: 0.8\n","Precisão: 0.6666666666666666\n","Recall: 0.8\n","F1-score: 0.72\n","Matriz de Confusão:\n","[[2 0 0]\n"," [0 2 0]\n"," [0 1 0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["\n","Os resultados mostram que o modelo está apresentando um desempenho bastante sólido, especialmente considerando a acurácia e o recall:\n","\n","**Acurácia: 0.8** - Isso indica que o modelo está acertando 80% das previsões em relação ao total de amostras. É um bom sinal de que o modelo tem um desempenho razoável na classificação geral.\n","\n","**Precisão: 0.67** - A precisão, que mede a proporção de verdadeiros positivos entre todas as previsões positivas, sugere que, embora o modelo tenha uma boa taxa de acertos, ele comete erros ao classificar algumas amostras.\n","\n","**Recall: 0.8** - Isso mostra que o modelo é capaz de identificar 80% das instâncias reais da classe positiva. Um recall alto é positivo, especialmente em contextos onde perder um caso positivo é crítico.\n","\n","**F1-score: 0.72** - Este valor é uma média harmônica da precisão e do recall, e um F1-score de 0.72 é um bom indicador de que o modelo está equilibrando bem entre a precisão e o recall.\n","\n","**A matriz de confusão indica que:**\n","* Para a **classe 0** (talvez \"delegação inadequada\"), o modelo acertou todas as previsões (2 acertos, 0 erros).\n","* Para a **classe 1** (talvez \"desvalorização\"), o modelo também acertou todas as previsões (2 acertos, 0 erros).\n","* Para a **classe 2** (talvez \"vida privada\"), o modelo identificou corretamente uma amostra, mas confundiu uma amostra, classificando-a como pertencente à classe 1.\n","\n","# Sugestões para Melhoria\n","**Aumento do Conjunto de Dados:** Se possível, aumentar a quantidade de dados de treinamento pode ajudar a melhorar o desempenho geral do modelo, especialmente em classes menos representadas.\n","\n","**Ajuste Fino dos Hiperparâmetros:** Continuar a explorar ajustes nos hiperparâmetros do MultinomialNB e do TfidfVectorizer, como o ajuste da regularização (alpha), o número de n-gramas, ou até mesmo testar outros vetorizadores, como o CountVectorizer.\n","\n","**Análise de Erros:** Examinar os casos que foram classificados incorretamente para entender por que isso aconteceu. Isso pode fornecer insights sobre o que melhorar, seja através de mais dados, mais características de entrada ou ajustando o modelo.\n","\n","**Exploração de Outros Modelos:** Considerar a aplicação de outros modelos de aprendizado de máquina, como SVM, árvores de decisão ou redes neurais, que podem capturar padrões diferentes nos dados.\n","\n","**Validação Cruzada:** Implementar validação cruzada para garantir que o modelo seja robusto e não apenas esteja se ajustando bem a um conjunto específico de dados."],"metadata":{"id":"4VH_STRvHYcA"}},{"cell_type":"code","source":["# Importar bibliotecas\n","import nltk\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import metrics\n","from imblearn.over_sampling import RandomOverSampler\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","# Baixar dados de análise de sentimentos do nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Função para ler o arquivo CSV de treinamento a partir de uma URL\n","def ler_csv_url(url):\n","    df = pd.read_csv(url)\n","    return df\n","\n","# Função para pré-processamento do texto: limpeza, remoção de stopwords e lematização\n","def preprocessamento_texto(textos):\n","    stop_words = set(stopwords.words('portuguese'))\n","    lemmatizer = WordNetLemmatizer()\n","\n","    textos_limpos = []\n","    for texto in textos:\n","        # Tokenizar e remover pontuação\n","        palavras = nltk.word_tokenize(texto.lower())\n","        palavras = [palavra for palavra in palavras if palavra.isalpha()]  # Mantém apenas palavras\n","\n","        # Remover stopwords e aplicar lematização\n","        palavras = [lemmatizer.lemmatize(palavra) for palavra in palavras if palavra not in stop_words]\n","        textos_limpos.append(\" \".join(palavras))\n","\n","    return textos_limpos\n","\n","# Função para balancear os dados com RandomOverSampler\n","def balancear_dados(X_train, y_train):\n","    ros = RandomOverSampler(random_state=42)\n","    X_res, y_res = ros.fit_resample(X_train, y_train)\n","    return X_res, y_res\n","\n","# Função para treinar o modelo com validação cruzada e ajuste de hiperparâmetros\n","def treinar_modelo(textos_treinamento, etiquetas_treinamento):\n","    # Dividir dados em treinamento e teste\n","    X_train, X_test, y_train, y_test = train_test_split(textos_treinamento, etiquetas_treinamento, test_size=0.2, random_state=42)\n","\n","    # Vetorizar o texto\n","    vectorizer = TfidfVectorizer(max_df=0.8, ngram_range=(1, 2))\n","    X_train_vect = vectorizer.fit_transform(X_train)\n","    X_test_vect = vectorizer.transform(X_test)\n","\n","    # Balancear os dados usando RandomOverSampler\n","    X_train_bal, y_train_bal = balancear_dados(X_train_vect, y_train)\n","\n","    # Treinar o modelo MultinomialNB\n","    modelo = MultinomialNB()\n","\n","    # Ajuste fino dos hiperparâmetros usando GridSearchCV\n","    parametros = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n","    grid_search = GridSearchCV(modelo, parametros, cv=5, scoring='f1_weighted')\n","    grid_search.fit(X_train_bal, y_train_bal)\n","\n","    print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n","    modelo = grid_search.best_estimator_\n","\n","    # Avaliar o modelo com validação cruzada\n","    scores = cross_val_score(modelo, X_train_bal, y_train_bal, cv=5, scoring='f1_weighted')\n","    print(\"F1-score médio com validação cruzada:\", np.mean(scores))\n","\n","    # Treinar o modelo final\n","    modelo.fit(X_train_bal, y_train_bal)\n","\n","    # Avaliar o modelo no conjunto de teste\n","    y_pred = modelo.predict(X_test_vect)\n","    print(\"Acurácia:\", metrics.accuracy_score(y_test, y_pred))\n","    print(\"Precisão:\", metrics.precision_score(y_test, y_pred, average='weighted'))\n","    print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='weighted'))\n","    print(\"F1-score:\", metrics.f1_score(y_test, y_pred, average='weighted'))\n","\n","    # Matriz de confusão\n","    print(\"Matriz de Confusão:\")\n","    cm = metrics.confusion_matrix(y_test, y_pred)\n","    print(cm)\n","\n","    # Análise de erros\n","    erros = pd.DataFrame({'fala': X_test, 'etiqueta_real': y_test, 'etiqueta_predita': y_pred})\n","    erros = erros[erros['etiqueta_real'] != erros['etiqueta_predita']]\n","    print(\"Análise de erros:\")\n","    print(erros)\n","\n","    # Relatório detalhado de métricas por classe\n","    print(\"Relatório de Classificação:\")\n","    print(metrics.classification_report(y_test, y_pred))\n","\n","    return modelo\n","\n","# URLs dos arquivos de treinamento\n","url_treinamento = 'https://raw.githubusercontent.com/jbetha/mba/refs/heads/main/Analise_Sentimento_Assedio_dados_treinamento.csv'\n","\n","# Ler o arquivo CSV de treinamento\n","df_treinamento = ler_csv_url(url_treinamento)\n","\n","# Pré-processar os textos de treinamento\n","df_treinamento['fala_limpa'] = preprocessamento_texto(df_treinamento['fala'])\n","\n","# Treinar o modelo com validação cruzada e ajuste de hiperparâmetros\n","modelo_comportamentos = treinar_modelo(df_treinamento['fala_limpa'], df_treinamento['comportamento'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAEM9w8gMfIQ","executionInfo":{"status":"ok","timestamp":1726932681995,"user_tz":180,"elapsed":587,"user":{"displayName":"Jaguaraci Silva","userId":"14528760357252352543"}},"outputId":"a4175901-9587-4240-f5bb-f2dbdd9bce97"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Melhores hiperparâmetros: {'alpha': 0.01}\n","F1-score médio com validação cruzada: 0.8806677843724904\n","Acurácia: 0.6578947368421053\n","Precisão: 0.7033492822966507\n","Recall: 0.6578947368421053\n","F1-score: 0.6583333333333334\n","Matriz de Confusão:\n","[[ 0  0  0  0  0  0]\n"," [ 1 14  3  0  0  0]\n"," [ 0  6  7  0  0  0]\n"," [ 0  0  0  2  0  0]\n"," [ 0  1  0  0  1  0]\n"," [ 0  1  1  0  0  1]]\n","Análise de erros:\n","                                                  fala         etiqueta_real  \\\n","175  priscila lourenço molina bastante buraco jagua...  delegação_inadequada   \n","65   jaguaraci batista silva falei pra agnes consig...        desvalorização   \n","141  priscila lourenço molina assim fica ficando cl...        desvalorização   \n","124  jaguaraci batista silva loga avd própria rede ...            isolamento   \n","164  priscila lourenço molina desconectou né ah lem...  delegação_inadequada   \n","120  priscila lourenço molina normalmente têm bloqu...          vida_privada   \n","66   priscila lourenço molina acho jaguar reuniões ...  delegação_inadequada   \n","56   jaguaraci batista silva além dessa parte ali m...        desvalorização   \n","168  jaguaraci batista silva conversa elane pediu d...          vida_privada   \n","67   jaguaraci batista silva aba aqui sobre mapa ca...        desvalorização   \n","132  jaguaraci batista silva acho gente colocou ali...        desvalorização   \n","169  elton oliveira ramalho acrescentaria negócio b...  delegação_inadequada   \n","163  priscila lourenço molina partir momento integr...        desvalorização   \n","\n","         etiqueta_predita  \n","175        desvalorização  \n","65   delegação_inadequada  \n","141  delegação_inadequada  \n","124  delegação_inadequada  \n","164        desvalorização  \n","120        desvalorização  \n","66         desvalorização  \n","56   delegação_inadequada  \n","168  delegação_inadequada  \n","67   delegação_inadequada  \n","132  delegação_inadequada  \n","169   ameaça_estabilidade  \n","163  delegação_inadequada  \n","Relatório de Classificação:\n","                      precision    recall  f1-score   support\n","\n"," ameaça_estabilidade       0.00      0.00      0.00         0\n","delegação_inadequada       0.64      0.78      0.70        18\n","      desvalorização       0.64      0.54      0.58        13\n","       falta_suporte       1.00      1.00      1.00         2\n","          isolamento       1.00      0.50      0.67         2\n","        vida_privada       1.00      0.33      0.50         3\n","\n","            accuracy                           0.66        38\n","           macro avg       0.71      0.52      0.57        38\n","        weighted avg       0.70      0.66      0.66        38\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}]}